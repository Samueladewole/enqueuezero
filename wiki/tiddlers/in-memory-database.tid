created: 20180611110456898
modified: 20180611111134587
title: in-memory-database
type: text/vnd.tiddlywiki

!! Context

Accessing data in memory can be faster than from disk.

In-memory database is a database that keeps the entire dataset in RAM. So it generally has better performance than on-disk databases.

!! Use

* When fast data access is a criterion.
* Used as caching layer in front of on-disk databases.

!! Common Patterns

Below compares some popular in-memory softwares like Memcached, Redis, etc.

!!! Socket Connection

Connecting to in-memory databases is usually through a UNIX socket. The in-memory database is designed to be connected fast, so the connection should never hang. We tend to set connection timeout very short, otherwise the frontend servers will have very serious latency and in worst case leading to system crash.

For the same reason, in-memory databases should respond quickly, usually in less than a millisecond.

The in-memory database often can easily handle massive amount of requests per second.

!!! Key - Value

The fundamental data structure that most in-memory database would provide is setting key-value pairs. It's often called key-value store as well.

For example, both in Memcached and Redis, it supports GET and SET commands:

```
> SET key "hello-world"
> GET key
"hello-world"
```

!!! GetMulti / SetMulti

Batch data operation is an enhancement on GET / SET. Instead of sending GET operations a thousand times, some in-memory databases provide batch get and get in a single round-trip of network connection.

For example, Redis provides MGET / MSET command:

```
> MSET key1 "hello" key2 "world"
> MGET key1 key2
1) "hello"
2) "world"
```

Not every in-memory database support GetMulti, in some case, it will need in-memory database client library provide a wrapper of GetMulti / SetMulti based on key hashing algorithm. However, the efficient will be less better.

!!! TTL

Key-values in in-memory databases are often required to set time-to-live (TTL) integers. The key-value pairs applying with TTL will be purged after timeout. This is to reduce the amount of less frequency data in memory, since memory is a very limited resource.

!!! Data Serialization

Most clients accept complex data structures but will serialize the data structure to a string or byte stream before storing into in-memory database.

Check [[Data Serialization|data-serialization]] fore more details.

!!! Richer Data Structures

Key-value cannot meet demands sometimes, therefore some in-memory databases provides richer data structures like relational rows

!!! Hashing

In-memory database clients could hash keys across multiple servers. This can ensure designated key will only appear in designated servers. This trick help us quickly identify which server stores data.

!!! Consistent Hashing

Consistent hashing is a special technique of hashing such that when the server number increased, only a portion of keys need to be rehash to the new server. Without consistent hashing, when the new server being added, data cross all servers will be re-hashed, which is unacceptable.

!!! High Availability

With the help of consistent hashing algorithm, hive availability can be achieved by simply deploying in-memory databases across multiple servers. It's the client's responsibility to ensure the key scattered properly.



!!! Snapshotting

Recoverability is a big challenge for In-memory databases. Imaging we're experiencing server reboot or process crash, then the data is lost.

Below lists two snapshotting strategies:

* No snapshotting
* Snapshotting regularly

!!!! No Snapshotting

Some choose no snapshotting at all. It means all data in in-memory database should be durable to lose.

A workaround of no snapshotting is to deploy in-memory database as a cluster. Each node in the cluster caches a portion of the entire dataset. The dataset might be replicated to multiple nodes. A few nodes crashing won't affect the function of the entire in-memory database cluster.

!!!! Snapshotting Strategy

Some offer an alternative solution of persisting data to disk. The requirement is it won't harm the advantage of in-memory. The trick is to sync data in a different thread at an interval frequency.

For example, Redis snapshotting can be achieved by setting in below command. It means Redis dump the dataset to disk every 6000 seconds if at least 1000 keys changed:

```
save 60 1000
```

It works by forking a child process for dumping. The child process writes all data in memory inherited from parent process to a file in disk.

It's recommended to always enable snapshotting. It's for faster reboot that heating the dataset slowing.

!!! Transaction Logging

Sometimes snapshotting entire dataset can take a huge amount of time. Another approach to boot disaster recovery is to do transaction logging. The theory of transaction logging is to save all UPDATE operations into disk. There are generally three options to flush the data to the disk:

* Save but slow: Flush to disk on every update.
* Less save but faster: Flush every a few seconds.
* Least save but fastest: Let Operating System do the flush.

The data consistency in in-memory database is often not a strong requirement. So we might possibly see the transaction logging file broken when process crashing. The solution of Redis is to run a command to fix the broken file:

```
$ redis-check-aof --fix
```

In this case, AOF means append-only fashion. It's a way of describing adding new transaction by appending to logs only, no update and no deletion.

!!! Hybrids with on-disk databases

The web application often wrap the cache functionality as a decorator to improve the performance of on-disk database. For example, below Python code demonstrates the pattern:

```
@cache(key='mymodel:{id}', ttl=3600)
def get_my_model(id):
    return Model.query.get(id)
```

Without changing too much on the logic, the function can now resolve data from cache first and only fetch data from on-disk database when cache missed.

It's a good strategy to reduce QoS on on-disk databases. The downside is that we might need to clean the cache when data needs to be updated.

!! Comparisons

!!! Memcached

Memcached is a free & open source, high-performance, distributed memory object caching system.

* Advantages
** Very simple.
** Widely supported.
* Disadvantages
** Sometimes operations might not operate successfully.

!!! Redis

> Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries.

* Advantages
** Rich document.
** Rich data structures and features.
** Small memory footprint.
** Good community.
** A nice inventor @antirez.
* Disadvantages
** Neither RDB and AOF is save. Although we must accept such trade-off.


!!! InMemory Engines

On-disk Databases like SQLite, MySQL also ship with an in-memory engine. For example, you can open a sqlite database only in memory: 

```
rc = sqlite3_open(":memory:", &db);
```

* Advantages
** No need to introduce more thing.
* Disadvantages
** Complicated compare to key-value option.
** No good support for in-memory database clustering. It's more often used as testing purpose.

!! Conclusion

An in-memory databases are faster than on-disk databases because disk access is slower than memory access. Meanwhile, to overcome the drawback of data losing easily, we have to invent things like snapshotting, transaction logging, consistent hashing, high availability. Still, people love in-memory databases when response time is really a criterion since it's probably the best solution. And in most case, Redis could be first choice.